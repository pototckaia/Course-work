{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1810, 55)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import mix as mix\n",
    "import db_column_name as db\n",
    "\n",
    "import numpy as np\n",
    "pd.set_option('precision', 10)\n",
    "\n",
    "import scipy.sparse\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "from pylab import rcParams\n",
    "# rcParams['figure.figsize'] = 7,5\n",
    "\n",
    "# offset can be 9, 21. 33, 45, 57, 69\n",
    "cn = db.ColumnName()\n",
    "\n",
    "target_minT = pd.read_csv('./data/31286_103.csv')\n",
    "mix.set_index_date(target_minT, cn.date)\n",
    "target_minT = target_minT.sort_index()\n",
    "\n",
    "X = pd.read_csv('./data/character_31286.csv')\n",
    "mix.set_index_date(X, cn.date)\n",
    "X = X.sort_index()\n",
    "\n",
    "X = X.drop([cn.point], axis=1)\n",
    "X = X[[x for x in X.columns if 'avg' in x or \n",
    "       x == cn.offset]]\n",
    "\n",
    "\n",
    "# X = X[X[cn.offset] == 69]\n",
    "# X = mix.year_less_eq(X, 2016)\n",
    "\n",
    "X = X.groupby([X.index.year, \n",
    "           X.index.month, \n",
    "           X.index.day]).mean()\n",
    "\n",
    "a = pd.DataFrame(X.index.tolist(), \n",
    "                 columns=['year','month','day'])\n",
    "X.index = pd.to_datetime(a)\n",
    "\n",
    "X = X.drop([cn.offset], axis=1)\n",
    "\n",
    "target_minT.index = target_minT.index.round('D')\n",
    "\n",
    "X[cn.value] = target_minT\n",
    "X = mix.clean_dataset(X)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1345, 56)\n"
     ]
    }
   ],
   "source": [
    "X['winsorized'] = X[cn.value]\n",
    "for index, row in X.iterrows(): \n",
    "    \n",
    "    offset_day = pd.to_timedelta(5, unit='day')\n",
    "    start_date = index - offset_day\n",
    "    end_date = index + offset_day\n",
    "    \n",
    "    s = X.iloc[(X.index >= start_date) & (X.index <= end_date)]\n",
    "    s = s[[cn.value]]\n",
    "    \n",
    "    q = s.quantile([0.05, 0.95])\n",
    "    \n",
    "    v = row[cn.value]\n",
    "    if (v < q.iloc[0, 0] or v > q.iloc[1, 0]):\n",
    "        X.drop([index], inplace=True)\n",
    "    \n",
    "print(X.shape)\n",
    "# X[['winsorized', cn.value]].plot(style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[cn.value] = X['winsorized']\n",
    "X = X.drop(['winsorized'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fir on one year\n",
      "Train size : 275 and test size : 1070\n",
      "Mean squared error on train 0.4149867168498243 and test 21.51979994918009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def fit(params, X, target, label_v):   \n",
    "    print(\"Fit timeSeriesSplit\")\n",
    "    for train_index, test_index in TimeSeriesSplit(5).split(X):   \n",
    "        test_index = [i for i in range(0, X.shape[0]) if i not in train_index]  \n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        target_train, target_test = target.iloc[train_index], target.iloc[test_index]\n",
    "        print(\"Train size : {} and test size : {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "        \n",
    "        reg = xgb.XGBRegressor(**params)\n",
    "\n",
    "        reg.fit(X_train, target_train)\n",
    "\n",
    "        target_test.loc[:, 'XGB prediction'] = reg.predict(X_test)\n",
    "        target_train.loc[:, 'XGB prediction'] = reg.predict(X_train)\n",
    "    \n",
    "        mix.print_mean(target_test, target_train, label_v, 'XGB prediction') \n",
    "        \n",
    "def fit_on_year(params, X_clear, target_minT, year):\n",
    "    print(\"Fir on one year\")\n",
    "    X_train, X_test = X_clear[X_clear.index.year == year], X_clear[X_clear.index.year != year]\n",
    "    target_train, target_test = target_minT.loc[X_train.index], target_minT.loc[X_test.index]\n",
    "    print(\"Train size : {} and test size : {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    reg = xgb.XGBRegressor(**params)\n",
    "\n",
    "    reg.fit(X_train, target_train)\n",
    "\n",
    "    target_test.loc[:, 'XGB prediction'] = reg.predict(X_test)\n",
    "    target_train.loc[:, 'XGB prediction'] = reg.predict(X_train)\n",
    "    mix.print_mean(target_test, target_train, cn.value, 'XGB prediction') \n",
    "    \n",
    "#     target_test.plot(style=\".\")\n",
    "    \n",
    "    \n",
    "default_params = {\n",
    "    'verbosity':0,\n",
    "    'max_depth': 6,\n",
    "    \n",
    "    'learning_rate': 0.05,\n",
    "#     'min_child_weight': 2,\n",
    "#     'subsample':0.8, \n",
    "#     'colsample_bytree':0.8,\n",
    "    'gamma': 16,\n",
    "}\n",
    "\n",
    "X_clear, target_minT = mix.getTarget(X)\n",
    "# fit(default_params, X_clear, target_minT, cn.value)\n",
    "\n",
    "\n",
    "params_one_year = {\n",
    "    'verbosity':0,\n",
    "    'max_depth': 5,\n",
    "    \n",
    "    'learning_rate': 0.05,\n",
    "    'min_child_weight': 6,\n",
    "#     'subsample':0.8, \n",
    "#     'colsample_bytree':0.8,\n",
    "#     'gamma': 16,\n",
    "}\n",
    "fit_on_year(params_one_year, X_clear, target_minT, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit timeSeriesSplit\n",
      "Train size : 104 and test size : 495\n",
      "Mean squared error on train 0.15919259860779927 and test 47.04572816230289\n",
      "Train size : 203 and test size : 396\n",
      "Mean squared error on train 0.2956102540699622 and test 63.889006962874625\n",
      "Train size : 302 and test size : 297\n",
      "Mean squared error on train 0.5009030176122053 and test 57.86842328345396\n",
      "Train size : 401 and test size : 198\n",
      "Mean squared error on train 0.7500755935110011 and test 64.07858943910234\n",
      "Train size : 500 and test size : 99\n",
      "Mean squared error on train 1.1038015880288825 and test 16.022720140622383\n"
     ]
    }
   ],
   "source": [
    "X_ = X.resample('3D').mean()\n",
    "X_ = mix.clean_dataset(X_)\n",
    "\n",
    "params_mean = {\n",
    "    'verbosity':0,\n",
    "    'max_depth': 4,\n",
    "    \n",
    "    'learning_rate': 0.07,\n",
    "    'min_child_weight': 10,\n",
    "#     'subsample':0.9, \n",
    "#     'colsample_bytree':0.8,\n",
    "#     'gamma': 7,\n",
    "}\n",
    "\n",
    "X_3mean, target_3mean = mix.getTarget(X_)\n",
    "fit(params_mean, X_3mean, target_3mean, cn.value)\n",
    "\n",
    "fit_on_year(params_mean, X_3mean, target_3mean, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : 225 and test size : 1120\n",
      "Mean squared error on train 0.2828700925151236 and test 41.91398933297258\n",
      "Train size : 449 and test size : 896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/xgboost-0.81-py3.7.egg/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/lib/python3.7/site-packages/xgboost-0.81-py3.7.egg/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on train 0.8669398073666773 and test 53.052260189825624\n",
      "Train size : 673 and test size : 672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/xgboost-0.81-py3.7.egg/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/lib/python3.7/site-packages/xgboost-0.81-py3.7.egg/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on train 1.5309101866801662 and test 54.837362523954525\n",
      "Train size : 897 and test size : 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/xgboost-0.81-py3.7.egg/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/lib/python3.7/site-packages/xgboost-0.81-py3.7.egg/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on train 1.7534929090738978 and test 71.320018620157\n",
      "Train size : 1121 and test size : 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/xgboost-0.81-py3.7.egg/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/lib/python3.7/site-packages/xgboost-0.81-py3.7.egg/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on train 2.079495022239914 and test 14.770041930705961\n"
     ]
    }
   ],
   "source": [
    "def fft_(X):\n",
    "    N = X.shape[0]\n",
    "    y = X[[cn.value]]\n",
    "    y.reset_index(inplace=True)\n",
    "    \n",
    "    Y = np.fft.fft(y[[cn.value]].values)\n",
    "    index = np.fft.fftfreq(N)\n",
    "    \n",
    "    amplit_Y  = np.abs(Y)\n",
    "    phase_Y = np.angle(Y)\n",
    "\n",
    "    fft_target = pd.DataFrame(np.hstack((amplit_Y, phase_Y)), columns=['amplitude', 'phase']) \n",
    "    fft_target.loc[:, cn.date] = y['index']\n",
    "    fft_target.set_index(index, inplace=True)\n",
    "    fft_X = X.set_index(index)\n",
    "    \n",
    "    return fft_X, fft_target\n",
    "\n",
    "fft_X, fft_target = fft_(X)\n",
    "fft_X.drop([cn.value], inplace=True, axis=1)\n",
    "real_X, real_target = mix.getTarget(X)\n",
    "\n",
    "def com(radii, angles):\n",
    "    return radii * np.around(np.exp(1j*angles), 10)\n",
    "\n",
    "def complex_(r, a):\n",
    "    Y_ = np.array(com(r, a).values)\n",
    "    Y_ = Y_.reshape((Y_.size, 1))\n",
    "    return Y_\n",
    "\n",
    "params = {\n",
    "    'verbosity':0,\n",
    "    'max_depth': 5,\n",
    "    \n",
    "    'learning_rate': 0.05,\n",
    "    'min_child_weight': 6,\n",
    "#     'subsample':0.8, \n",
    "#     'colsample_bytree':0.8,\n",
    "#     'gamma': 12,\n",
    "}\n",
    "\n",
    "for train_index, test_index in TimeSeriesSplit(5).split(fft_X):\n",
    "    test_index = [i for i in range(0, fft_X.shape[0]) if i not in train_index]  \n",
    "\n",
    "    fft_X_train, fft_X_test = fft_X.iloc[train_index], fft_X.iloc[test_index]\n",
    "    fft_target_train, fft_target_test = fft_target.iloc[train_index], fft_target.iloc[test_index]\n",
    "    print(\"Train size : {} and test size : {}\".format(fft_X_train.shape[0], fft_X_test.shape[0]))\n",
    "    \n",
    "    real_target_train = real_target.loc[fft_target_train[cn.date]]\n",
    "    real_target_test = real_target.loc[fft_target_test[cn.date]]\n",
    "    \n",
    "    reg = xgb.XGBRegressor(**params)\n",
    "    reg.fit(fft_X_train, fft_target_train.loc[:, 'amplitude'])\n",
    "\n",
    "    fft_target_test['Predict am'] = reg.predict(fft_X_test)\n",
    "    fft_target_train['Predict am'] = reg.predict(fft_X_train)\n",
    "\n",
    "    Y = complex_(fft_target_train.loc[:, 'Predict am'], fft_target_train.loc[:, 'phase'])\n",
    "    real_target_train['FFT prediction'] = np.fft.ifft(Y).real\n",
    "\n",
    "    Y = complex_(fft_target_test.loc[:, 'Predict am'], fft_target_test.loc[:, 'phase'])\n",
    "    real_target_test['FFT prediction'] = np.fft.ifft(Y).real\n",
    "\n",
    "    mix.print_mean(real_target_test, real_target_train, cn.value, 'FFT prediction')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
